# ğŸ—£ï¸ RAG Q&A Conversation Bot (LangChain + Streamlit + PDF + Memory)

An interactive, **conversational chatbot** that performs Retrieval-Augmented Generation (RAG) over a PDF document using **LangChain**, with **chat history support** and a clean **Streamlit UI**. Ask follow-up questions and get contextually aware answers using local document data.

---

## ğŸ“‚ Project Structure

```
RAG Q&A Conversation/
â”œâ”€â”€ app.py         # Streamlit app with PDF upload, vector search, and chat memory
â””â”€â”€ temp.pdf       # Sample document for testing
```

---

## ğŸš€ Features

- ğŸ“„ Upload and query PDFs using LangChainâ€™s document loaders
- ğŸ§  Maintains conversation history using LangChain memory
- ğŸ” Retrieves contextually relevant chunks via retriever
- ğŸ¤– Generates responses using OpenAI or other LLMs
- ğŸŒ Streamlit interface with real-time Q&A

---

## ğŸ› ï¸ How to Run

```bash
cd "RAG Q&A Conversation"
pip install -r requirements.txt
streamlit run app.py
```

> ğŸ“ Replace `temp.pdf` with your own document or allow uploads in the UI.

---

## ğŸ’¬ Example Conversation

- **You**: â€œWhatâ€™s this document about?â€
- **Bot**: â€œIt discusses neural network attention mechanisms...â€
- **You**: â€œExplain the use of softmax here.â€

---

## ğŸ”­ Future Enhancements

- Add PDF uploader to replace hardcoded file
- Enable multi-file RAG
- Support local LLMs (e.g., Ollama) for private use

---


## ğŸ“« Contact

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Aparna-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/aparna-k-628005167/)
